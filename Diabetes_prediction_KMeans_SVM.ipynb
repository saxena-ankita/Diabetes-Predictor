{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting to know some information about the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   int64\n",
       "Glucose                       int64\n",
       "BloodPressure                 int64\n",
       "SkinThickness                 int64\n",
       "Insulin                       int64\n",
       "BMI                         float64\n",
       "DiabetesPedigreeFunction    float64\n",
       "Age                           int64\n",
       "Outcome                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if there are any missing values in the dataset\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, there are no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome\n",
      "0    500\n",
      "1    268\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('Outcome').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code line shows that in the whole dataset consisting of 768 records, 500 are non-diabetic while 268 are diabetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Outcome', ylabel='count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Outcome', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 4, 3, 1, 7, 3, 9, 2, 7, 7, 4, 7, 5, 1, 9, 1, 7, 3, 3, 1, 7,\n",
       "       4, 7, 6, 6, 4, 6, 6, 7, 7, 1, 3, 0, 7, 1, 7, 0, 0, 1, 4, 7, 7, 1,\n",
       "       4, 4, 7, 0, 0, 9, 3, 3, 0, 8, 8, 0, 8, 6, 4, 6, 9, 7, 0, 6, 7, 0,\n",
       "       7, 7, 3, 6, 3, 6, 7, 8, 0, 0, 0, 0, 9, 7, 7, 9, 3, 0, 7, 6, 0, 3,\n",
       "       6, 7, 0, 1, 3, 7, 3, 1, 0, 3, 3, 1, 4, 4, 7, 3, 0, 6, 7, 6, 0, 3,\n",
       "       6, 2, 3, 0, 1, 4, 7, 0, 0, 3, 6, 0, 3, 7, 7, 3, 6, 3, 6, 7, 1, 7,\n",
       "       1, 0, 3, 6, 3, 3, 7, 8, 7, 7, 3, 7, 8, 0, 0, 6, 4, 0, 1, 7, 6, 2,\n",
       "       4, 4, 3, 6, 3, 6, 4, 6, 8, 0, 7, 6, 4, 7, 7, 3, 7, 6, 9, 3, 3, 6,\n",
       "       0, 6, 4, 7, 0, 3, 0, 0, 7, 4, 2, 3, 6, 6, 7, 6, 4, 9, 0, 1, 7, 3,\n",
       "       3, 8, 7, 7, 7, 3, 1, 7, 8, 4, 3, 4, 0, 4, 4, 6, 1, 8, 6, 6, 0, 7,\n",
       "       2, 4, 9, 1, 3, 0, 7, 4, 5, 3, 7, 8, 0, 7, 3, 4, 1, 4, 4, 7, 0, 3,\n",
       "       7, 1, 1, 4, 7, 5, 8, 7, 7, 7, 3, 0, 1, 7, 0, 7, 8, 6, 6, 9, 0, 4,\n",
       "       7, 3, 9, 7, 0, 9, 0, 3, 7, 3, 7, 3, 0, 6, 7, 8, 4, 6, 6, 4, 7, 6,\n",
       "       2, 1, 3, 3, 3, 3, 1, 1, 4, 6, 8, 1, 1, 7, 9, 6, 3, 7, 4, 6, 6, 6,\n",
       "       1, 1, 0, 6, 6, 3, 7, 3, 3, 4, 6, 4, 1, 7, 7, 4, 7, 1, 6, 4, 6, 3,\n",
       "       7, 3, 9, 7, 3, 8, 9, 7, 1, 4, 6, 3, 0, 7, 7, 6, 3, 9, 3, 0, 0, 7,\n",
       "       0, 3, 0, 4, 1, 9, 3, 8, 8, 4, 7, 4, 8, 3, 7, 0, 3, 6, 2, 3, 3, 3,\n",
       "       6, 8, 3, 3, 4, 3, 3, 0, 1, 3, 6, 3, 7, 7, 8, 3, 1, 4, 2, 3, 4, 8,\n",
       "       6, 7, 0, 4, 0, 7, 6, 0, 4, 1, 7, 0, 4, 2, 0, 1, 8, 3, 1, 2, 0, 4,\n",
       "       0, 6, 1, 3, 3, 7, 1, 8, 9, 1, 6, 1, 9, 3, 3, 7, 0, 9, 4, 4, 0, 7,\n",
       "       4, 3, 6, 7, 7, 4, 3, 3, 3, 3, 3, 7, 1, 9, 3, 4, 7, 3, 1, 3, 3, 0,\n",
       "       3, 0, 7, 6, 0, 3, 9, 6, 4, 7, 7, 7, 7, 7, 1, 6, 3, 7, 8, 7, 3, 6,\n",
       "       9, 1, 2, 8, 0, 4, 3, 0, 0, 6, 9, 4, 7, 3, 6, 1, 3, 0, 0, 3, 0, 0,\n",
       "       6, 1, 3, 7, 0, 1, 0, 0, 3, 6, 1, 7, 0, 8, 3, 6, 9, 7, 7, 0, 3, 6,\n",
       "       1, 7, 6, 7, 3, 9, 3, 9, 7, 0, 1, 6, 1, 1, 0, 3, 3, 1, 1, 1, 4, 4,\n",
       "       7, 3, 7, 3, 3, 1, 0, 7, 0, 0, 7, 8, 3, 3, 0, 3, 0, 6, 6, 1, 0, 7,\n",
       "       3, 6, 8, 3, 6, 7, 7, 4, 4, 0, 7, 7, 2, 0, 7, 7, 6, 9, 7, 6, 7, 3,\n",
       "       1, 1, 0, 9, 4, 6, 7, 9, 7, 6, 9, 7, 8, 3, 8, 1, 6, 1, 8, 0, 6, 7,\n",
       "       7, 0, 7, 9, 6, 0, 4, 6, 7, 3, 7, 7, 7, 0, 7, 3, 7, 1, 0, 7, 7, 3,\n",
       "       3, 3, 3, 7, 4, 9, 6, 2, 6, 6, 6, 0, 3, 6, 3, 7, 6, 2, 3, 1, 7, 3,\n",
       "       4, 4, 1, 6, 7, 6, 4, 7, 1, 6, 1, 0, 3, 1, 7, 4, 4, 0, 7, 8, 3, 4,\n",
       "       3, 7, 7, 1, 7, 0, 1, 1, 7, 4, 3, 6, 0, 2, 6, 9, 6, 7, 1, 7, 4, 9,\n",
       "       3, 0, 9, 8, 4, 6, 8, 7, 7, 8, 7, 8, 1, 0, 1, 0, 0, 1, 6, 6, 7, 7,\n",
       "       1, 7, 4, 0, 3, 7, 6, 1, 7, 0, 6, 0, 6, 7, 6, 3, 6, 7, 6, 6, 4, 3,\n",
       "       1, 4, 7, 3, 0, 2, 4, 6, 7, 7, 7, 4, 0, 4, 0, 1, 7, 6, 7, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KMeans_Clustering = KMeans(n_clusters=10, random_state=0) \n",
    "KMeans_Clustering.fit(data)\n",
    "KMeans_Clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 4, 3, 1, 7, 3, 9, 2, 7, 7, 4, 7, 5, 1, 9, 1, 7, 3, 3, 1, 7,\n",
       "       4, 7, 6, 6, 4, 6, 6, 7, 7, 1, 3, 0, 7, 1, 7, 0, 0, 1, 4, 7, 7, 1,\n",
       "       4, 4, 7, 0, 0, 9, 3, 3, 0, 8, 8, 0, 8, 6, 4, 6, 9, 7, 0, 6, 7, 0,\n",
       "       7, 7, 3, 6, 3, 6, 7, 8, 0, 0, 0, 0, 9, 7, 7, 9, 3, 0, 7, 6, 0, 3,\n",
       "       6, 7, 0, 1, 3, 7, 3, 1, 0, 3, 3, 1, 4, 4, 7, 3, 0, 6, 7, 6, 0, 3,\n",
       "       6, 2, 3, 0, 1, 4, 7, 0, 0, 3, 6, 0, 3, 7, 7, 3, 6, 3, 6, 7, 1, 7,\n",
       "       1, 0, 3, 6, 3, 3, 7, 8, 7, 7, 3, 7, 8, 0, 0, 6, 4, 0, 1, 7, 6, 2,\n",
       "       4, 4, 3, 6, 3, 6, 4, 6, 8, 0, 7, 6, 4, 7, 7, 3, 7, 6, 9, 3, 3, 6,\n",
       "       0, 6, 4, 7, 0, 3, 0, 0, 7, 4, 2, 3, 6, 6, 7, 6, 4, 9, 0, 1, 7, 3,\n",
       "       3, 8, 7, 7, 7, 3, 1, 7, 8, 4, 3, 4, 0, 4, 4, 6, 1, 8, 6, 6, 0, 7,\n",
       "       2, 4, 9, 1, 3, 0, 7, 4, 5, 3, 7, 8, 0, 7, 3, 4, 1, 4, 4, 7, 0, 3,\n",
       "       7, 1, 1, 4, 7, 5, 8, 7, 7, 7, 3, 0, 1, 7, 0, 7, 8, 6, 6, 9, 0, 4,\n",
       "       7, 3, 9, 7, 0, 9, 0, 3, 7, 3, 7, 3, 0, 6, 7, 8, 4, 6, 6, 4, 7, 6,\n",
       "       2, 1, 3, 3, 3, 3, 1, 1, 4, 6, 8, 1, 1, 7, 9, 6, 3, 7, 4, 6, 6, 6,\n",
       "       1, 1, 0, 6, 6, 3, 7, 3, 3, 4, 6, 4, 1, 7, 7, 4, 7, 1, 6, 4, 6, 3,\n",
       "       7, 3, 9, 7, 3, 8, 9, 7, 1, 4, 6, 3, 0, 7, 7, 6, 3, 9, 3, 0, 0, 7,\n",
       "       0, 3, 0, 4, 1, 9, 3, 8, 8, 4, 7, 4, 8, 3, 7, 0, 3, 6, 2, 3, 3, 3,\n",
       "       6, 8, 3, 3, 4, 3, 3, 0, 1, 3, 6, 3, 7, 7, 8, 3, 1, 4, 2, 3, 4, 8,\n",
       "       6, 7, 0, 4, 0, 7, 6, 0, 4, 1, 7, 0, 4, 2, 0, 1, 8, 3, 1, 2, 0, 4,\n",
       "       0, 6, 1, 3, 3, 7, 1, 8, 9, 1, 6, 1, 9, 3, 3, 7, 0, 9, 4, 4, 0, 7,\n",
       "       4, 3, 6, 7, 7, 4, 3, 3, 3, 3, 3, 7, 1, 9, 3, 4, 7, 3, 1, 3, 3, 0,\n",
       "       3, 0, 7, 6, 0, 3, 9, 6, 4, 7, 7, 7, 7, 7, 1, 6, 3, 7, 8, 7, 3, 6,\n",
       "       9, 1, 2, 8, 0, 4, 3, 0, 0, 6, 9, 4, 7, 3, 6, 1, 3, 0, 0, 3, 0, 0,\n",
       "       6, 1, 3, 7, 0, 1, 0, 0, 3, 6, 1, 7, 0, 8, 3, 6, 9, 7, 7, 0, 3, 6,\n",
       "       1, 7, 6, 7, 3, 9, 3, 9, 7, 0, 1, 6, 1, 1, 0, 3, 3, 1, 1, 1, 4, 4,\n",
       "       7, 3, 7, 3, 3, 1, 0, 7, 0, 0, 7, 8, 3, 3, 0, 3, 0, 6, 6, 1, 0, 7,\n",
       "       3, 6, 8, 3, 6, 7, 7, 4, 4, 0, 7, 7, 2, 0, 7, 7, 6, 9, 7, 6, 7, 3,\n",
       "       1, 1, 0, 9, 4, 6, 7, 9, 7, 6, 9, 7, 8, 3, 8, 1, 6, 1, 8, 0, 6, 7,\n",
       "       7, 0, 7, 9, 6, 0, 4, 6, 7, 3, 7, 7, 7, 0, 7, 3, 7, 1, 0, 7, 7, 3,\n",
       "       3, 3, 3, 7, 4, 9, 6, 2, 6, 6, 6, 0, 3, 6, 3, 7, 6, 2, 3, 1, 7, 3,\n",
       "       4, 4, 1, 6, 7, 6, 4, 7, 1, 6, 1, 0, 3, 1, 7, 4, 4, 0, 7, 8, 3, 4,\n",
       "       3, 7, 7, 1, 7, 0, 1, 1, 7, 4, 3, 6, 0, 2, 6, 9, 6, 7, 1, 7, 4, 9,\n",
       "       3, 0, 9, 8, 4, 6, 8, 7, 7, 8, 7, 8, 1, 0, 1, 0, 0, 1, 6, 6, 7, 7,\n",
       "       1, 7, 4, 0, 3, 7, 6, 1, 7, 0, 6, 0, 6, 7, 6, 3, 6, 7, 6, 6, 4, 3,\n",
       "       1, 4, 7, 3, 0, 2, 4, 6, 7, 7, 7, 4, 0, 4, 0, 1, 7, 6, 7, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KMeans_labels = KMeans_Clustering.labels_\n",
    "KMeans_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 80), (0, 109), (3, 135), (1, 81), (7, 164), (9, 36), (2, 16), (5, 3), (6, 107), (8, 37)]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(Counter(KMeans_labels).keys(), Counter(KMeans_labels).values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I have to segregate each cluster on the basis of their outcome values.\n",
    "Then I have to delete from each cluster the records in minority in terms of the outcome values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KMeans_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  33,\n",
       "  37,\n",
       "  38,\n",
       "  47,\n",
       "  48,\n",
       "  52,\n",
       "  55,\n",
       "  62,\n",
       "  65,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  83,\n",
       "  86,\n",
       "  90,\n",
       "  96,\n",
       "  104,\n",
       "  108,\n",
       "  113,\n",
       "  117,\n",
       "  118,\n",
       "  121,\n",
       "  133,\n",
       "  145,\n",
       "  146,\n",
       "  149,\n",
       "  163,\n",
       "  176,\n",
       "  180,\n",
       "  182,\n",
       "  183,\n",
       "  194,\n",
       "  210,\n",
       "  218,\n",
       "  225,\n",
       "  232,\n",
       "  240,\n",
       "  253,\n",
       "  256,\n",
       "  262,\n",
       "  268,\n",
       "  270,\n",
       "  276,\n",
       "  310,\n",
       "  342,\n",
       "  349,\n",
       "  350,\n",
       "  352,\n",
       "  354,\n",
       "  367,\n",
       "  381,\n",
       "  398,\n",
       "  400,\n",
       "  403,\n",
       "  407,\n",
       "  410,\n",
       "  416,\n",
       "  418,\n",
       "  434,\n",
       "  438,\n",
       "  461,\n",
       "  463,\n",
       "  466,\n",
       "  488,\n",
       "  491,\n",
       "  492,\n",
       "  501,\n",
       "  502,\n",
       "  504,\n",
       "  505,\n",
       "  510,\n",
       "  512,\n",
       "  513,\n",
       "  518,\n",
       "  525,\n",
       "  537,\n",
       "  542,\n",
       "  556,\n",
       "  558,\n",
       "  559,\n",
       "  564,\n",
       "  566,\n",
       "  570,\n",
       "  581,\n",
       "  585,\n",
       "  596,\n",
       "  613,\n",
       "  617,\n",
       "  621,\n",
       "  629,\n",
       "  634,\n",
       "  649,\n",
       "  671,\n",
       "  677,\n",
       "  687,\n",
       "  694,\n",
       "  705,\n",
       "  717,\n",
       "  719,\n",
       "  720,\n",
       "  729,\n",
       "  735,\n",
       "  737,\n",
       "  752,\n",
       "  760,\n",
       "  762,\n",
       "  767],\n",
       " [4,\n",
       "  14,\n",
       "  16,\n",
       "  20,\n",
       "  31,\n",
       "  35,\n",
       "  39,\n",
       "  43,\n",
       "  91,\n",
       "  95,\n",
       "  99,\n",
       "  114,\n",
       "  130,\n",
       "  132,\n",
       "  150,\n",
       "  195,\n",
       "  204,\n",
       "  214,\n",
       "  223,\n",
       "  236,\n",
       "  243,\n",
       "  244,\n",
       "  254,\n",
       "  287,\n",
       "  292,\n",
       "  293,\n",
       "  297,\n",
       "  298,\n",
       "  308,\n",
       "  309,\n",
       "  320,\n",
       "  325,\n",
       "  338,\n",
       "  356,\n",
       "  382,\n",
       "  390,\n",
       "  405,\n",
       "  411,\n",
       "  414,\n",
       "  420,\n",
       "  424,\n",
       "  427,\n",
       "  429,\n",
       "  452,\n",
       "  458,\n",
       "  476,\n",
       "  485,\n",
       "  499,\n",
       "  507,\n",
       "  511,\n",
       "  516,\n",
       "  528,\n",
       "  538,\n",
       "  540,\n",
       "  541,\n",
       "  545,\n",
       "  546,\n",
       "  547,\n",
       "  555,\n",
       "  569,\n",
       "  594,\n",
       "  595,\n",
       "  609,\n",
       "  611,\n",
       "  633,\n",
       "  657,\n",
       "  662,\n",
       "  668,\n",
       "  670,\n",
       "  673,\n",
       "  685,\n",
       "  688,\n",
       "  689,\n",
       "  700,\n",
       "  716,\n",
       "  718,\n",
       "  721,\n",
       "  726,\n",
       "  733,\n",
       "  748,\n",
       "  763],\n",
       " [8,\n",
       "  111,\n",
       "  153,\n",
       "  186,\n",
       "  220,\n",
       "  286,\n",
       "  370,\n",
       "  392,\n",
       "  409,\n",
       "  415,\n",
       "  486,\n",
       "  584,\n",
       "  645,\n",
       "  655,\n",
       "  695,\n",
       "  753],\n",
       " [3,\n",
       "  6,\n",
       "  18,\n",
       "  19,\n",
       "  32,\n",
       "  50,\n",
       "  51,\n",
       "  68,\n",
       "  70,\n",
       "  82,\n",
       "  87,\n",
       "  92,\n",
       "  94,\n",
       "  97,\n",
       "  98,\n",
       "  103,\n",
       "  109,\n",
       "  112,\n",
       "  119,\n",
       "  122,\n",
       "  125,\n",
       "  127,\n",
       "  134,\n",
       "  136,\n",
       "  137,\n",
       "  142,\n",
       "  156,\n",
       "  158,\n",
       "  169,\n",
       "  173,\n",
       "  174,\n",
       "  181,\n",
       "  187,\n",
       "  197,\n",
       "  198,\n",
       "  203,\n",
       "  208,\n",
       "  224,\n",
       "  229,\n",
       "  234,\n",
       "  241,\n",
       "  252,\n",
       "  265,\n",
       "  271,\n",
       "  273,\n",
       "  275,\n",
       "  288,\n",
       "  289,\n",
       "  290,\n",
       "  291,\n",
       "  302,\n",
       "  313,\n",
       "  315,\n",
       "  316,\n",
       "  329,\n",
       "  331,\n",
       "  334,\n",
       "  341,\n",
       "  346,\n",
       "  348,\n",
       "  353,\n",
       "  358,\n",
       "  365,\n",
       "  368,\n",
       "  371,\n",
       "  372,\n",
       "  373,\n",
       "  376,\n",
       "  377,\n",
       "  379,\n",
       "  380,\n",
       "  383,\n",
       "  385,\n",
       "  389,\n",
       "  393,\n",
       "  413,\n",
       "  421,\n",
       "  422,\n",
       "  431,\n",
       "  432,\n",
       "  441,\n",
       "  446,\n",
       "  447,\n",
       "  448,\n",
       "  449,\n",
       "  450,\n",
       "  454,\n",
       "  457,\n",
       "  459,\n",
       "  460,\n",
       "  462,\n",
       "  467,\n",
       "  478,\n",
       "  482,\n",
       "  490,\n",
       "  497,\n",
       "  500,\n",
       "  503,\n",
       "  508,\n",
       "  514,\n",
       "  520,\n",
       "  526,\n",
       "  532,\n",
       "  534,\n",
       "  543,\n",
       "  544,\n",
       "  551,\n",
       "  553,\n",
       "  554,\n",
       "  562,\n",
       "  563,\n",
       "  565,\n",
       "  572,\n",
       "  575,\n",
       "  593,\n",
       "  607,\n",
       "  625,\n",
       "  631,\n",
       "  637,\n",
       "  638,\n",
       "  639,\n",
       "  640,\n",
       "  650,\n",
       "  652,\n",
       "  656,\n",
       "  659,\n",
       "  672,\n",
       "  680,\n",
       "  682,\n",
       "  692,\n",
       "  704,\n",
       "  730,\n",
       "  741,\n",
       "  747,\n",
       "  751],\n",
       " [0,\n",
       "  2,\n",
       "  11,\n",
       "  22,\n",
       "  26,\n",
       "  40,\n",
       "  44,\n",
       "  45,\n",
       "  58,\n",
       "  100,\n",
       "  101,\n",
       "  115,\n",
       "  148,\n",
       "  154,\n",
       "  155,\n",
       "  160,\n",
       "  166,\n",
       "  178,\n",
       "  185,\n",
       "  192,\n",
       "  207,\n",
       "  209,\n",
       "  211,\n",
       "  212,\n",
       "  221,\n",
       "  227,\n",
       "  235,\n",
       "  237,\n",
       "  238,\n",
       "  245,\n",
       "  263,\n",
       "  280,\n",
       "  283,\n",
       "  294,\n",
       "  304,\n",
       "  317,\n",
       "  319,\n",
       "  323,\n",
       "  327,\n",
       "  339,\n",
       "  355,\n",
       "  361,\n",
       "  363,\n",
       "  378,\n",
       "  391,\n",
       "  394,\n",
       "  399,\n",
       "  404,\n",
       "  408,\n",
       "  417,\n",
       "  436,\n",
       "  437,\n",
       "  440,\n",
       "  445,\n",
       "  455,\n",
       "  470,\n",
       "  489,\n",
       "  495,\n",
       "  548,\n",
       "  549,\n",
       "  579,\n",
       "  580,\n",
       "  598,\n",
       "  622,\n",
       "  642,\n",
       "  660,\n",
       "  661,\n",
       "  666,\n",
       "  675,\n",
       "  676,\n",
       "  681,\n",
       "  691,\n",
       "  702,\n",
       "  708,\n",
       "  728,\n",
       "  746,\n",
       "  749,\n",
       "  754,\n",
       "  759,\n",
       "  761],\n",
       " [13, 228, 247],\n",
       " [24,\n",
       "  25,\n",
       "  27,\n",
       "  28,\n",
       "  57,\n",
       "  59,\n",
       "  63,\n",
       "  69,\n",
       "  71,\n",
       "  85,\n",
       "  88,\n",
       "  105,\n",
       "  107,\n",
       "  110,\n",
       "  120,\n",
       "  126,\n",
       "  128,\n",
       "  135,\n",
       "  147,\n",
       "  152,\n",
       "  157,\n",
       "  159,\n",
       "  161,\n",
       "  165,\n",
       "  171,\n",
       "  175,\n",
       "  177,\n",
       "  188,\n",
       "  189,\n",
       "  191,\n",
       "  213,\n",
       "  216,\n",
       "  217,\n",
       "  259,\n",
       "  260,\n",
       "  277,\n",
       "  281,\n",
       "  282,\n",
       "  285,\n",
       "  295,\n",
       "  301,\n",
       "  305,\n",
       "  306,\n",
       "  307,\n",
       "  311,\n",
       "  312,\n",
       "  318,\n",
       "  326,\n",
       "  328,\n",
       "  340,\n",
       "  345,\n",
       "  369,\n",
       "  374,\n",
       "  384,\n",
       "  396,\n",
       "  402,\n",
       "  419,\n",
       "  428,\n",
       "  442,\n",
       "  465,\n",
       "  469,\n",
       "  477,\n",
       "  483,\n",
       "  493,\n",
       "  498,\n",
       "  506,\n",
       "  515,\n",
       "  521,\n",
       "  527,\n",
       "  530,\n",
       "  539,\n",
       "  567,\n",
       "  568,\n",
       "  573,\n",
       "  576,\n",
       "  588,\n",
       "  591,\n",
       "  599,\n",
       "  603,\n",
       "  610,\n",
       "  614,\n",
       "  620,\n",
       "  623,\n",
       "  644,\n",
       "  646,\n",
       "  647,\n",
       "  648,\n",
       "  651,\n",
       "  654,\n",
       "  663,\n",
       "  665,\n",
       "  669,\n",
       "  693,\n",
       "  696,\n",
       "  698,\n",
       "  709,\n",
       "  722,\n",
       "  723,\n",
       "  732,\n",
       "  736,\n",
       "  738,\n",
       "  740,\n",
       "  742,\n",
       "  744,\n",
       "  745,\n",
       "  755,\n",
       "  765],\n",
       " [5,\n",
       "  9,\n",
       "  10,\n",
       "  12,\n",
       "  17,\n",
       "  21,\n",
       "  23,\n",
       "  29,\n",
       "  30,\n",
       "  34,\n",
       "  36,\n",
       "  41,\n",
       "  42,\n",
       "  46,\n",
       "  61,\n",
       "  64,\n",
       "  66,\n",
       "  67,\n",
       "  72,\n",
       "  79,\n",
       "  80,\n",
       "  84,\n",
       "  89,\n",
       "  93,\n",
       "  102,\n",
       "  106,\n",
       "  116,\n",
       "  123,\n",
       "  124,\n",
       "  129,\n",
       "  131,\n",
       "  138,\n",
       "  140,\n",
       "  141,\n",
       "  143,\n",
       "  151,\n",
       "  164,\n",
       "  167,\n",
       "  168,\n",
       "  170,\n",
       "  179,\n",
       "  184,\n",
       "  190,\n",
       "  196,\n",
       "  200,\n",
       "  201,\n",
       "  202,\n",
       "  205,\n",
       "  219,\n",
       "  226,\n",
       "  230,\n",
       "  233,\n",
       "  239,\n",
       "  242,\n",
       "  246,\n",
       "  249,\n",
       "  250,\n",
       "  251,\n",
       "  255,\n",
       "  257,\n",
       "  264,\n",
       "  267,\n",
       "  272,\n",
       "  274,\n",
       "  278,\n",
       "  284,\n",
       "  299,\n",
       "  303,\n",
       "  314,\n",
       "  321,\n",
       "  322,\n",
       "  324,\n",
       "  330,\n",
       "  333,\n",
       "  337,\n",
       "  343,\n",
       "  344,\n",
       "  351,\n",
       "  362,\n",
       "  366,\n",
       "  386,\n",
       "  387,\n",
       "  397,\n",
       "  401,\n",
       "  406,\n",
       "  423,\n",
       "  433,\n",
       "  439,\n",
       "  443,\n",
       "  444,\n",
       "  451,\n",
       "  456,\n",
       "  464,\n",
       "  471,\n",
       "  472,\n",
       "  473,\n",
       "  474,\n",
       "  475,\n",
       "  479,\n",
       "  481,\n",
       "  496,\n",
       "  509,\n",
       "  517,\n",
       "  523,\n",
       "  524,\n",
       "  529,\n",
       "  531,\n",
       "  536,\n",
       "  550,\n",
       "  552,\n",
       "  557,\n",
       "  560,\n",
       "  571,\n",
       "  577,\n",
       "  578,\n",
       "  582,\n",
       "  583,\n",
       "  586,\n",
       "  587,\n",
       "  590,\n",
       "  592,\n",
       "  600,\n",
       "  602,\n",
       "  605,\n",
       "  615,\n",
       "  616,\n",
       "  618,\n",
       "  624,\n",
       "  626,\n",
       "  627,\n",
       "  628,\n",
       "  630,\n",
       "  632,\n",
       "  635,\n",
       "  636,\n",
       "  641,\n",
       "  653,\n",
       "  658,\n",
       "  664,\n",
       "  667,\n",
       "  674,\n",
       "  678,\n",
       "  683,\n",
       "  684,\n",
       "  686,\n",
       "  690,\n",
       "  699,\n",
       "  701,\n",
       "  711,\n",
       "  712,\n",
       "  714,\n",
       "  724,\n",
       "  725,\n",
       "  727,\n",
       "  731,\n",
       "  734,\n",
       "  739,\n",
       "  743,\n",
       "  750,\n",
       "  756,\n",
       "  757,\n",
       "  758,\n",
       "  764,\n",
       "  766],\n",
       " [53,\n",
       "  54,\n",
       "  56,\n",
       "  73,\n",
       "  139,\n",
       "  144,\n",
       "  162,\n",
       "  199,\n",
       "  206,\n",
       "  215,\n",
       "  231,\n",
       "  248,\n",
       "  258,\n",
       "  279,\n",
       "  296,\n",
       "  335,\n",
       "  359,\n",
       "  360,\n",
       "  364,\n",
       "  375,\n",
       "  388,\n",
       "  395,\n",
       "  412,\n",
       "  425,\n",
       "  480,\n",
       "  487,\n",
       "  519,\n",
       "  561,\n",
       "  574,\n",
       "  606,\n",
       "  608,\n",
       "  612,\n",
       "  679,\n",
       "  707,\n",
       "  710,\n",
       "  713,\n",
       "  715],\n",
       " [7,\n",
       "  15,\n",
       "  49,\n",
       "  60,\n",
       "  78,\n",
       "  81,\n",
       "  172,\n",
       "  193,\n",
       "  222,\n",
       "  261,\n",
       "  266,\n",
       "  269,\n",
       "  300,\n",
       "  332,\n",
       "  336,\n",
       "  347,\n",
       "  357,\n",
       "  426,\n",
       "  430,\n",
       "  435,\n",
       "  453,\n",
       "  468,\n",
       "  484,\n",
       "  494,\n",
       "  522,\n",
       "  533,\n",
       "  535,\n",
       "  589,\n",
       "  597,\n",
       "  601,\n",
       "  604,\n",
       "  619,\n",
       "  643,\n",
       "  697,\n",
       "  703,\n",
       "  706]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KMeans_Clusters = []\n",
    "Cluster_Row = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    for j in range(0, 768):\n",
    "        if(KMeans_labels[j]==i) :\n",
    "            Cluster_Row.append(j)\n",
    "    KMeans_Clusters.append(Cluster_Row)\n",
    "    Cluster_Row = []\n",
    "\n",
    "KMeans_Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code-line just above, I got all the indices of records present in a particular cluster. Now, I need to segregate the diabetic and non-diabetic outcome out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 97 \t 12\n",
      "1 \t 39 \t 42\n",
      "2 \t 5 \t 11\n",
      "3 \t 122 \t 13\n",
      "4 \t 25 \t 55\n",
      "5 \t 2 \t 1\n",
      "6 \t 63 \t 44\n",
      "7 \t 107 \t 57\n",
      "8 \t 20 \t 17\n",
      "9 \t 20 \t 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(539, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetic = 0\n",
    "non_diabetic = 0\n",
    "\n",
    "df = data\n",
    "\n",
    "for i in range(10) :\n",
    "    (diabetic, non_diabetic) = (0, 0)\n",
    "    for j in KMeans_Clusters[i] :\n",
    "        if(data.iloc[j]['Outcome']==0.0) :\n",
    "            non_diabetic = non_diabetic + 1\n",
    "        else :\n",
    "            diabetic = diabetic + 1\n",
    "    print(i, \"\\t\", non_diabetic, \"\\t\", diabetic)\n",
    "    \n",
    "    #deleting lesser value\n",
    "    if(diabetic < non_diabetic) :\n",
    "        for j in KMeans_Clusters[i] :\n",
    "            if(data.iloc[j]['Outcome']==1.0) :\n",
    "                df = df.drop(j)\n",
    "    else :\n",
    "        for j in KMeans_Clusters[i] :\n",
    "            if(data.iloc[j]['Outcome']==0.0) :\n",
    "                df = df.drop(j)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got my dataframe for performing SVM which is named here as 'df'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STARTING THE PREDICTION PROCESS BY USING SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the data and labels\n",
    "X = df.drop(columns = 'Outcome', axis=1)\n",
    "Y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              6      148             72             35        0  33.6   \n",
      "1              1       85             66             29        0  26.6   \n",
      "2              8      183             64              0        0  23.3   \n",
      "3              1       89             66             23       94  28.1   \n",
      "4              0      137             40             35      168  43.1   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "761            9      170             74             31        0  44.0   \n",
      "762            9       89             62              0        0  22.5   \n",
      "764            2      122             70             27        0  36.8   \n",
      "765            5      121             72             23      112  26.2   \n",
      "767            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  \n",
      "0                       0.627   50  \n",
      "1                       0.351   31  \n",
      "2                       0.672   32  \n",
      "3                       0.167   21  \n",
      "4                       2.288   33  \n",
      "..                        ...  ...  \n",
      "761                     0.403   43  \n",
      "762                     0.142   33  \n",
      "764                     0.340   27  \n",
      "765                     0.245   30  \n",
      "767                     0.315   23  \n",
      "\n",
      "[539 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "761    1\n",
      "762    0\n",
      "764    0\n",
      "765    0\n",
      "767    0\n",
      "Name: Outcome, Length: 539, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA STANDARDISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_data = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.75261109  1.00100946  0.15777171 ...  0.30712838  0.4937673\n",
      "   1.52742974]\n",
      " [-0.80401738 -0.97224482 -0.17397972 ... -0.57354905 -0.31911849\n",
      "  -0.09961498]\n",
      " [ 1.37526248  2.09726184 -0.28456353 ... -0.98872555  0.62630303\n",
      "  -0.01398105]\n",
      " ...\n",
      " [-0.49269168  0.18665055  0.0471879  ...  0.70972377 -0.35151611\n",
      "  -0.44215071]\n",
      " [ 0.4412854   0.15532905  0.15777171 ... -0.62387348 -0.63131376\n",
      "  -0.18524892]\n",
      " [-0.80401738 -0.72167285  0.0471879  ... -0.09546702 -0.42514707\n",
      "  -0.78468645]]\n"
     ]
    }
   ],
   "source": [
    "print(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = standardized_data\n",
    "Y = df['Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN - TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.1, stratify=Y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(539, 8) (485, 8) (54, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the support vector Machine Classifier\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score on the training data\n",
    "X_train_prediction = classifier.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the training data :  0.9257731958762887\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the training data : ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score on the test data\n",
    "X_test_prediction = classifier.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the test data :  0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the test data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERFORMING 10-FOLD CROSS VALIDATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the above hybrid model using k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# # create dataset\n",
    "# X, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# # prepare the cross-validation procedure\n",
    "# cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# # create model\n",
    "# model = LogisticRegression()\n",
    "# # evaluate model\n",
    "# scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# # report performance\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.924 (0.032)\n"
     ]
    }
   ],
   "source": [
    "# prepare the cross-validation procedure\n",
    "cross_validation = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(classifier, X, Y, scoring='accuracy', cv=cross_validation, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING THE MODEL TO DISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'hybrid_diabetes_detector.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKING A PREDICTIVE SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4412854   1.5647964   0.15777171 -0.06250347  0.945035   -0.6741979\n",
      "   0.37595776  1.61306367]]\n",
      "[1]\n",
      "The person is diabetic\n"
     ]
    }
   ],
   "source": [
    "input_data = (5,166,72,19,175,25.8,0.587,51)\n",
    "\n",
    "# changing the input_data to numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# reshape the array as we are predicting for one instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "# standardize the input data\n",
    "std_data = scaler.transform(input_data_reshaped)\n",
    "print(std_data)\n",
    "\n",
    "prediction = classifier.predict(std_data)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "  print('The person is not diabetic')\n",
    "else:\n",
    "  print('The person is diabetic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
